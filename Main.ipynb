{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e362dda4-5601-4af5-9346-b66b69be7cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ollama\n",
    "import io\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "# Initialize Pydantic AI Agent using Ollama\n",
    "agent = Agent(\n",
    "    \"llama3:8b\",  # Use Ollama's locally running Llama 3 model\n",
    "    system_prompt=\"You are an AI assistant that analyzes CSV data and provides concise answers.\"\n",
    ")\n",
    "\n",
    "# Global variable to store uploaded data\n",
    "data = None\n",
    "\n",
    "# Function to upload CSV file\n",
    "def upload_file(file):\n",
    "    global data\n",
    "    try:\n",
    "        data = pd.read_csv(file.name)\n",
    "        return \"File uploaded successfully!\"\n",
    "    except Exception as e:\n",
    "        return f\"Error parsing CSV: {str(e)}\"\n",
    "\n",
    "# Function to process user query\n",
    "def process_query(user_query):\n",
    "    global data\n",
    "    if data is None:\n",
    "        return \"Please upload a CSV file first.\"\n",
    "\n",
    "    try:\n",
    "        # Use Pydantic AI Agent for query processing\n",
    "        ai_response = agent.run_sync(f\"Data: {data.head(5).to_string()}\\nQuery: {user_query}\")\n",
    "\n",
    "        # Generate response using Ollama\n",
    "        response = ollama.chat(model=\"llama3:8b\", messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI trained to analyze CSV data and answer queries.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Data: {data.head(5).to_string()}\\nQuery: {user_query}\"}\n",
    "        ])\n",
    "\n",
    "        return f\"**Agent Response:** {ai_response.data}\\n\\n**LLM Response:** {response['message']['content']}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error processing query: {str(e)}\"\n",
    "\n",
    "# Function to plot graph\n",
    "def plot_graph(x_column, y_column):\n",
    "    global data\n",
    "    if data is None:\n",
    "        return \"Please upload a CSV file first.\", None\n",
    "    \n",
    "    if x_column not in data.columns or y_column not in data.columns:\n",
    "        return \"Invalid column selection.\", None\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(data[x_column], data[y_column], marker=\"o\", linestyle=\"-\")\n",
    "    plt.xlabel(x_column)\n",
    "    plt.ylabel(y_column)\n",
    "    plt.title(f\"{y_column} vs {x_column}\")\n",
    "\n",
    "    # Save plot to a buffer\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    buf.seek(0)\n",
    "\n",
    "    return \"Graph generated successfully!\", buf\n",
    "\n",
    "# Gradio Interface\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# CSV Chatbot with Pydantic AI, LLM, and Graph Plotting\")\n",
    "    \n",
    "    file_upload = gr.File(label=\"Upload CSV\", file_types=[\".csv\"])\n",
    "    upload_btn = gr.Button(\"Upload\")\n",
    "    upload_output = gr.Textbox(label=\"Upload Status\")\n",
    "\n",
    "    query_input = gr.Textbox(label=\"Ask a question about the CSV\")\n",
    "    query_btn = gr.Button(\"Submit\")\n",
    "    query_output = gr.Textbox(label=\"Answer\")\n",
    "\n",
    "    x_column = gr.Textbox(label=\"X-axis column\")\n",
    "    y_column = gr.Textbox(label=\"Y-axis column\")\n",
    "    plot_btn = gr.Button(\"Plot Graph\")\n",
    "    plot_output = gr.Textbox(label=\"Graph Status\")\n",
    "    plot_image = gr.Image(label=\"Graph\")\n",
    "\n",
    "    upload_btn.click(upload_file, inputs=[file_upload], outputs=[upload_output])\n",
    "    query_btn.click(process_query, inputs=[query_input], outputs=[query_output])\n",
    "    plot_btn.click(plot_graph, inputs=[x_column, y_column], outputs=[plot_output, plot_image])\n",
    "\n",
    "# Run the app\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa84eda-1087-4c06-9a95-4aae7340457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harvard University is located in Cambridge, Massachusetts.\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai import Agent\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "MODEL_ID = 'llama3:8b'\n",
    "\n",
    "OLLAMA_SERVER_ENDPOINT = 'http://localhost:11434/v1'\n",
    "\n",
    "model_ollama = OpenAIModel(\n",
    "    model_name = MODEL_ID,  # Ensure the correct model name\n",
    "    base_url= OLLAMA_SERVER_ENDPOINT, # Ollama's OpenAI-compatible endpoint\n",
    ")\n",
    "\n",
    "# Initialize Pydantic AI agent\n",
    "agent = Agent(model = model_ollama, system_prompt ='Reply in 1 sentence')\n",
    "\n",
    "result = agent.run_sync(\"What is the location of Harvard University?\")\n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73738db7-0ab4-4341-bf35-b0e0f431848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import nest_asyncio\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "# Fix event loop issue in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Ollama Model Configuration\n",
    "MODEL_ID = \"llama3\"  # Ensure you have pulled the correct model\n",
    "OLLAMA_SERVER_ENDPOINT = \"http://localhost:11434/v1\"\n",
    "\n",
    "# Initialize the OpenAI-compatible model with Ollama\n",
    "model_ollama = OpenAIModel(\n",
    "    model_name=MODEL_ID,\n",
    "    base_url=OLLAMA_SERVER_ENDPOINT,\n",
    ")\n",
    "\n",
    "# Initialize Pydantic AI Agent\n",
    "agent = Agent(\n",
    "    model=model_ollama,\n",
    "    system_prompt=\"You are an AI assistant that analyzes CSV data and provides concise answers.\"\n",
    ")\n",
    "\n",
    "# Global variable to store uploaded CSV data\n",
    "data = None\n",
    "\n",
    "# ============================\n",
    "# File Handling\n",
    "# ============================\n",
    "def upload_file(file):\n",
    "    \"\"\"Handles CSV file upload and parsing.\"\"\"\n",
    "    global data\n",
    "    try:\n",
    "        data = pd.read_csv(file.name)\n",
    "        return f\"‚úÖ File uploaded successfully! Rows: {data.shape[0]}, Columns: {data.shape[1]}\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error parsing CSV: {str(e)}\"\n",
    "\n",
    "# ============================\n",
    "# Query Processing (Pydantic AI + Ollama)\n",
    "# ============================\n",
    "def process_query(user_query):\n",
    "    \"\"\"Processes user query using Pydantic AI & Ollama.\"\"\"\n",
    "    global data\n",
    "    if data is None:\n",
    "        return \"‚ö† Please upload a CSV file first.\"\n",
    "\n",
    "    try:\n",
    "        # Convert entire CSV to string\n",
    "        csv_string = data.to_csv(index=False)\n",
    "\n",
    "        SAFE_LIMIT = 15000  # Increase limit for more context\n",
    "\n",
    "        if len(csv_string) <= SAFE_LIMIT:\n",
    "            data_for_ai = csv_string  # Full CSV if within limit\n",
    "        else:\n",
    "            # Provide structured context for larger files\n",
    "            sample_rows = data.head(15).to_csv(index=False)\n",
    "            column_info = data.describe(include=\"all\").to_csv(index=False)\n",
    "            data_for_ai = f\"Sample Data:\\n{sample_rows}\\n\\nColumn Summary:\\n{column_info}\"\n",
    "\n",
    "        # **Enhanced Query Prompt**\n",
    "        prompt = (\n",
    "            \"You are a data analyst AI. Use the given CSV data to answer the query accurately.\\n\"\n",
    "            \"If the query requires numerical computation, analyze the values correctly.\\n\"\n",
    "            \"If the query asks about patterns, trends, or correlations, provide insights based on the data.\\n\"\n",
    "            \"Do NOT just return column names; analyze the content.\\n\\n\"\n",
    "            f\"Data:\\n{data_for_ai}\\n\\nQuery: {user_query}\"\n",
    "        )\n",
    "\n",
    "        # Use Pydantic AI Agent for query processing\n",
    "        ai_response = agent.run_sync(prompt)\n",
    "\n",
    "        return f\"ü§ñ **AI Response:** {ai_response.data}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error processing query: {str(e)}\"\n",
    "\n",
    "# ============================\n",
    "# Graph Plotting (Fixed)\n",
    "# ============================\n",
    "def plot_graph(x_column, y_column):\n",
    "    \"\"\"Generates a graph from selected CSV columns.\"\"\"\n",
    "    global data\n",
    "    if data is None:\n",
    "        return \"‚ö† Please upload a CSV file first.\", None\n",
    "    \n",
    "    # Ensure columns exist\n",
    "    if x_column not in data.columns or y_column not in data.columns:\n",
    "        return f\"‚ùå Columns '{x_column}' or '{y_column}' not found in CSV.\", None\n",
    "    \n",
    "    # Ensure the selected columns contain numeric values\n",
    "    if not pd.api.types.is_numeric_dtype(data[x_column]):\n",
    "        return f\"‚ùå Column '{x_column}' is not numeric.\", None\n",
    "    if not pd.api.types.is_numeric_dtype(data[y_column]):\n",
    "        return f\"‚ùå Column '{y_column}' is not numeric.\", None\n",
    "\n",
    "    # Plot the graph\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(data[x_column], data[y_column], marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "    plt.xlabel(x_column)\n",
    "    plt.ylabel(y_column)\n",
    "    plt.title(f\"{y_column} vs {x_column}\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the plot as an image\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    buf.seek(0)\n",
    "    plt.close()  # Close the plot to free memory\n",
    "\n",
    "    return \"‚úÖ Graph generated successfully!\", buf\n",
    "\n",
    "# ============================\n",
    "# Gradio Interface\n",
    "# ============================\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# üìä CSV Chatbot with Pydantic AI, LLM, and Graph Plotting\")\n",
    "    \n",
    "    file_upload = gr.File(label=\"üìÇ Upload CSV\", file_types=[\".csv\"])\n",
    "    upload_btn = gr.Button(\"Upload\")\n",
    "    upload_output = gr.Textbox(label=\"Upload Status\")\n",
    "\n",
    "    query_input = gr.Textbox(label=\"üí¨ Ask a question about the CSV\")\n",
    "    query_btn = gr.Button(\"Submit\")\n",
    "    query_output = gr.Textbox(label=\"ü§ñ AI Answer\")\n",
    "\n",
    "    x_column = gr.Textbox(label=\"üìâ X-axis column\")\n",
    "    y_column = gr.Textbox(label=\"üìà Y-axis column\")\n",
    "    plot_btn = gr.Button(\"üìä Plot Graph\")\n",
    "    plot_output = gr.Textbox(label=\"Graph Status\")\n",
    "    plot_image = gr.Image(label=\"Graph\")\n",
    "\n",
    "    upload_btn.click(upload_file, inputs=[file_upload], outputs=[upload_output])\n",
    "    query_btn.click(process_query, inputs=[query_input], outputs=[query_output])\n",
    "    plot_btn.click(plot_graph, inputs=[x_column, y_column], outputs=[plot_output, plot_image])\n",
    "\n",
    "# Run the Gradio app\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6f87b9a-041c-442b-846b-3a68899b45eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "import json\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "import pydantic_ai as pai\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import traceback\n",
    "\n",
    "# Define the Pydantic AI models for structured LLM responses\n",
    "class GraphRequest(BaseModel):\n",
    "    \"\"\"A request to create a graph from CSV data.\"\"\"\n",
    "    graph_type: str = Field(..., description=\"Type of graph to create (e.g., 'bar', 'line', 'scatter', 'histogram', 'boxplot', 'heatmap')\")\n",
    "    x_column: str = Field(..., description=\"Column name for the x-axis\")\n",
    "    y_column: Optional[str] = Field(None, description=\"Column name for the y-axis (optional for some plot types)\")\n",
    "    title: str = Field(..., description=\"Title of the graph\")\n",
    "    hue: Optional[str] = Field(None, description=\"Column name for color grouping (optional)\")\n",
    "    \n",
    "class CSVQuestion(BaseModel):\n",
    "    \"\"\"A query about CSV data that can be answered with text or require a graph.\"\"\"\n",
    "    question_type: str = Field(..., description=\"Either 'text' for a text answer or 'graph' for a visualization\")\n",
    "    answer: Optional[str] = Field(None, description=\"The text answer if question_type is 'text'\")\n",
    "    graph_request: Optional[GraphRequest] = Field(None, description=\"The graph specification if question_type is 'graph'\")\n",
    "\n",
    "# Ollama LLM client\n",
    "class OllamaClient:\n",
    "    def _init_(self, model_name=\"llama3.1-8b-q4_0\"):\n",
    "        self.model_name = model_name\n",
    "        self.api_url = \"http://localhost:11434/api/generate\"\n",
    "        \n",
    "    def generate(self, prompt, system_prompt=None):\n",
    "        payload = {\n",
    "            \"model\": self.model_name,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        if system_prompt:\n",
    "            payload[\"system\"] = system_prompt\n",
    "            \n",
    "        try:\n",
    "            response = requests.post(self.api_url, json=payload)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get(\"response\", \"\")\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {str(e)}\"\n",
    "\n",
    "# CSV Data Processor\n",
    "class CSVDataProcessor:\n",
    "    def _init_(self):\n",
    "        self.df = None\n",
    "        self.file_path = None\n",
    "        self.columns = []\n",
    "        self.summary = {}\n",
    "        \n",
    "    def load_csv(self, file_path):\n",
    "        try:\n",
    "            self.df = pd.read_csv(file_path)\n",
    "            self.file_path = file_path\n",
    "            self.columns = list(self.df.columns)\n",
    "            self.generate_summary()\n",
    "            return True, \"CSV file loaded successfully.\"\n",
    "        except Exception as e:\n",
    "            return False, f\"Error loading CSV file: {str(e)}\"\n",
    "    \n",
    "    def generate_summary(self):\n",
    "        \"\"\"Generate a summary of the CSV data\"\"\"\n",
    "        if self.df is None:\n",
    "            return\n",
    "        \n",
    "        self.summary = {\n",
    "            \"num_rows\": len(self.df),\n",
    "            \"num_columns\": len(self.columns),\n",
    "            \"column_types\": {col: str(self.df[col].dtype) for col in self.columns},\n",
    "            \"sample_data\": self.df.head(5).to_dict(orient=\"records\"),\n",
    "            \"numeric_columns\": list(self.df.select_dtypes(include=['int64', 'float64']).columns),\n",
    "            \"categorical_columns\": list(self.df.select_dtypes(include=['object', 'category']).columns),\n",
    "            \"missing_values\": self.df.isna().sum().to_dict()\n",
    "        }\n",
    "        \n",
    "        # Add basic statistics for numeric columns\n",
    "        self.summary[\"statistics\"] = {}\n",
    "        for col in self.summary[\"numeric_columns\"]:\n",
    "            self.summary[\"statistics\"][col] = {\n",
    "                \"min\": float(self.df[col].min()) if not pd.isna(self.df[col].min()) else None,\n",
    "                \"max\": float(self.df[col].max()) if not pd.isna(self.df[col].max()) else None,\n",
    "                \"mean\": float(self.df[col].mean()) if not pd.isna(self.df[col].mean()) else None,\n",
    "                \"median\": float(self.df[col].median()) if not pd.isna(self.df[col].median()) else None\n",
    "            }\n",
    "        \n",
    "        # Add basic statistics for categorical columns\n",
    "        for col in self.summary[\"categorical_columns\"]:\n",
    "            value_counts = self.df[col].value_counts().head(5).to_dict()\n",
    "            self.summary[\"statistics\"][col] = {\n",
    "                \"unique_values\": self.df[col].nunique(),\n",
    "                \"top_values\": {str(k): int(v) for k, v in value_counts.items()}\n",
    "            }\n",
    "\n",
    "# LLM Query Processor\n",
    "class LLMQueryProcessor:\n",
    "    def _init_(self, csv_processor: CSVDataProcessor):\n",
    "        self.csv_processor = csv_processor\n",
    "        self.llm_client = OllamaClient()\n",
    "        self.system_prompt = \"\"\"\n",
    "        You are a data analysis assistant that interprets questions about CSV data and provides \n",
    "        answers based on analysis of the data. For each question, determine whether the answer \n",
    "        should be textual or requires a graph.\n",
    "        \n",
    "        If the question requires analysis that can be answered with text, generate a concise, accurate \n",
    "        answer based on the data.\n",
    "        \n",
    "        If the question would benefit from a visualization, specify the appropriate graph type, \n",
    "        columns, and styling parameters.\n",
    "        \n",
    "        Always return your response as valid JSON matching the CSVQuestion schema.\n",
    "        \"\"\"\n",
    "        \n",
    "    def process_query(self, query: str) -> CSVQuestion:\n",
    "        if self.csv_processor.df is None:\n",
    "            return CSVQuestion(\n",
    "                question_type=\"text\",\n",
    "                answer=\"Please upload a CSV file first.\"\n",
    "            )\n",
    "        \n",
    "        try:\n",
    "            # Prepare context about the data\n",
    "            df_info = json.dumps(self.csv_processor.summary, default=str)\n",
    "            prompt = f\"\"\"\n",
    "            # CSV Data Information\n",
    "            {df_info}\n",
    "            \n",
    "            # User Question\n",
    "            {query}\n",
    "            \n",
    "            # Response Instructions\n",
    "            Analyze the question and the CSV data information. Then, respond with a valid JSON object \n",
    "            matching the CSVQuestion schema which includes either:\n",
    "            1. For analysis questions: question_type=\"text\" and answer=<your analytical answer>\n",
    "            2. For visualization questions: question_type=\"graph\" and graph_request containing graph_type, x_column, y_column (if applicable), title, and hue (if applicable)\n",
    "            \n",
    "            The graph types supported are: bar, line, scatter, histogram, boxplot, heatmap.\n",
    "            \n",
    "            # CSVQuestion Schema\n",
    "            \n",
    "            class GraphRequest:\n",
    "                graph_type: str  # Type of graph (bar, line, scatter, histogram, boxplot, heatmap)\n",
    "                x_column: str  # Column for x-axis\n",
    "                y_column: Optional[str]  # Column for y-axis (if applicable)\n",
    "                title: str  # Graph title\n",
    "                hue: Optional[str]  # Column for color grouping (if applicable)\n",
    "                \n",
    "            class CSVQuestion:\n",
    "                question_type: str  # Either 'text' or 'graph'\n",
    "                answer: Optional[str]  # Text answer if question_type is 'text'\n",
    "                graph_request: Optional[GraphRequest]  # Graph specification if question_type is 'graph'\n",
    "            \n",
    "            \n",
    "            Return only the JSON object, without any additional text:\n",
    "            \"\"\"\n",
    "            \n",
    "            # Get response from LLM\n",
    "            llm_response = self.llm_client.generate(prompt, self.system_prompt)\n",
    "            \n",
    "            # Parse the response as JSON\n",
    "            response_dict = json.loads(llm_response.strip())\n",
    "            \n",
    "            # Construct the CSVQuestion model\n",
    "            if response_dict.get(\"question_type\") == \"graph\" and response_dict.get(\"graph_request\"):\n",
    "                graph_data = response_dict[\"graph_request\"]\n",
    "                graph_request = GraphRequest(\n",
    "                    graph_type=graph_data[\"graph_type\"],\n",
    "                    x_column=graph_data[\"x_column\"],\n",
    "                    y_column=graph_data.get(\"y_column\"),\n",
    "                    title=graph_data[\"title\"],\n",
    "                    hue=graph_data.get(\"hue\")\n",
    "                )\n",
    "                result = CSVQuestion(\n",
    "                    question_type=\"graph\",\n",
    "                    graph_request=graph_request\n",
    "                )\n",
    "            else:\n",
    "                result = CSVQuestion(\n",
    "                    question_type=\"text\",\n",
    "                    answer=response_dict.get(\"answer\", \"I couldn't analyze this question properly.\")\n",
    "                )\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_details = traceback.format_exc()\n",
    "            print(f\"Error processing query: {error_details}\")\n",
    "            return CSVQuestion(\n",
    "                question_type=\"text\",\n",
    "                answer=f\"Error processing your query: {str(e)}\"\n",
    "            )\n",
    "\n",
    "# Graph Generator\n",
    "class GraphGenerator:\n",
    "    def _init_(self, csv_processor: CSVDataProcessor):\n",
    "        self.csv_processor = csv_processor\n",
    "        \n",
    "    def create_graph(self, graph_request: GraphRequest) -> Optional[str]:\n",
    "        if self.csv_processor.df is None:\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            df = self.csv_processor.df\n",
    "            \n",
    "            # Ensure columns exist in dataframe\n",
    "            if graph_request.x_column not in df.columns:\n",
    "                return None\n",
    "                \n",
    "            if graph_request.y_column and graph_request.y_column not in df.columns:\n",
    "                return None\n",
    "                \n",
    "            if graph_request.hue and graph_request.hue not in df.columns:\n",
    "                graph_request.hue = None\n",
    "                \n",
    "            # Create the appropriate graph based on the request\n",
    "            if graph_request.graph_type == \"bar\":\n",
    "                if graph_request.y_column:\n",
    "                    sns.barplot(x=df[graph_request.x_column], y=df[graph_request.y_column], \n",
    "                              hue=df[graph_request.hue] if graph_request.hue else None)\n",
    "                else:\n",
    "                    df[graph_request.x_column].value_counts().plot(kind='bar')\n",
    "                    \n",
    "            elif graph_request.graph_type == \"line\":\n",
    "                if graph_request.y_column:\n",
    "                    sns.lineplot(x=df[graph_request.x_column], y=df[graph_request.y_column], \n",
    "                               hue=df[graph_request.hue] if graph_request.hue else None)\n",
    "                else:\n",
    "                    df[graph_request.x_column].plot(kind='line')\n",
    "                    \n",
    "            elif graph_request.graph_type == \"scatter\":\n",
    "                if graph_request.y_column:\n",
    "                    sns.scatterplot(x=df[graph_request.x_column], y=df[graph_request.y_column], \n",
    "                                  hue=df[graph_request.hue] if graph_request.hue else None)\n",
    "                else:\n",
    "                    return None  # Scatter plot requires both x and y\n",
    "                    \n",
    "            elif graph_request.graph_type == \"histogram\":\n",
    "                sns.histplot(df[graph_request.x_column], kde=True)\n",
    "                \n",
    "            elif graph_request.graph_type == \"boxplot\":\n",
    "                if graph_request.y_column:\n",
    "                    sns.boxplot(x=df[graph_request.x_column], y=df[graph_request.y_column], \n",
    "                              hue=df[graph_request.hue] if graph_request.hue else None)\n",
    "                else:\n",
    "                    sns.boxplot(x=df[graph_request.x_column])\n",
    "                    \n",
    "            elif graph_request.graph_type == \"heatmap\":\n",
    "                if graph_request.y_column:\n",
    "                    # Create a pivot table for the heatmap\n",
    "                    heatmap_data = df.pivot_table(\n",
    "                        index=graph_request.x_column,\n",
    "                        columns=graph_request.y_column,\n",
    "                        values=graph_request.hue if graph_request.hue else df.select_dtypes(include=['number']).columns[0],\n",
    "                        aggfunc='mean'\n",
    "                    )\n",
    "                    sns.heatmap(heatmap_data, annot=True, cmap=\"YlGnBu\")\n",
    "                else:\n",
    "                    # If only x is provided, create a correlation heatmap of numeric columns\n",
    "                    correlation = df.select_dtypes(include=['number']).corr()\n",
    "                    sns.heatmap(correlation, annot=True, cmap=\"coolwarm\")\n",
    "            \n",
    "            plt.title(graph_request.title)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Convert plot to base64 image\n",
    "            buffer = BytesIO()\n",
    "            plt.savefig(buffer, format='png')\n",
    "            buffer.seek(0)\n",
    "            image_png = buffer.getvalue()\n",
    "            plt.close()\n",
    "            \n",
    "            return base64.b64encode(image_png).decode('utf-8')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating graph: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# Gradio Application\n",
    "class GradioCSVApp:\n",
    "    def _init_(self):\n",
    "        self.csv_processor = CSVDataProcessor()\n",
    "        self.llm_processor = LLMQueryProcessor(self.csv_processor)\n",
    "        self.graph_generator = GraphGenerator(self.csv_processor)\n",
    "        \n",
    "    def upload_csv(self, file):\n",
    "        if file is None:\n",
    "            return \"Please upload a CSV file.\", None\n",
    "            \n",
    "        success, message = self.csv_processor.load_csv(file.name)\n",
    "        if success:\n",
    "            # Generate and return summary information\n",
    "            columns = \", \".join(self.csv_processor.columns)\n",
    "            num_rows = self.csv_processor.summary[\"num_rows\"]\n",
    "            num_cols = self.csv_processor.summary[\"num_columns\"]\n",
    "            return f\"‚úÖ CSV loaded successfully: {num_rows} rows, {num_cols} columns.\\n\\nColumns: {columns}\", None\n",
    "        else:\n",
    "            return f\"‚ùå {message}\", None\n",
    "    \n",
    "    def process_question(self, question, state):\n",
    "        if self.csv_processor.df is None:\n",
    "            return \"Please upload a CSV file first.\", None, state\n",
    "            \n",
    "        try:\n",
    "            # Process the question using the LLM\n",
    "            result = self.llm_processor.process_query(question)\n",
    "            \n",
    "            if result.question_type == \"text\":\n",
    "                return result.answer, None, state\n",
    "                \n",
    "            elif result.question_type == \"graph\":\n",
    "                # Generate the graph from the request\n",
    "                graph_image = self.graph_generator.create_graph(result.graph_request)\n",
    "                \n",
    "                if graph_image:\n",
    "                    graph_description = (\n",
    "                        f\"üìä Graph: {result.graph_request.title}\\n\"\n",
    "                        f\"Type: {result.graph_request.graph_type}\\n\"\n",
    "                        f\"X-axis: {result.graph_request.x_column}\\n\"\n",
    "                        f\"Y-axis: {result.graph_request.y_column if result.graph_request.y_column else 'N/A'}\\n\"\n",
    "                        f\"Color grouping: {result.graph_request.hue if result.graph_request.hue else 'N/A'}\"\n",
    "                    )\n",
    "                    return graph_description, graph_image, state\n",
    "                else:\n",
    "                    return \"Failed to create the requested graph. Please check your question and try again.\", None, state\n",
    "        \n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\", None, state\n",
    "\n",
    "    def launch(self):\n",
    "        with gr.Blocks(title=\"CSV Question Answering & Visualization\", theme=gr.themes.Soft()) as app:\n",
    "            gr.Markdown(\"# CSV Question Answering & Visualization\")\n",
    "            gr.Markdown(\"Upload a CSV file, then ask questions about the data. The system can provide text answers or generate visualizations.\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    file_input = gr.File(label=\"Upload CSV File (max 25MB)\")\n",
    "                    upload_button = gr.Button(\"Upload and Process\")\n",
    "                    file_info = gr.Textbox(label=\"File Information\", interactive=False)\n",
    "                    \n",
    "                with gr.Column(scale=2):\n",
    "                    question_input = gr.Textbox(label=\"Ask a question about your data\", placeholder=\"e.g., What is the average price? or Show me a histogram of prices\")\n",
    "                    submit_button = gr.Button(\"Submit Question\")\n",
    "                    \n",
    "                    answer_output = gr.Textbox(label=\"Answer\", interactive=False)\n",
    "                    graph_output = gr.Image(label=\"Visualization\", interactive=False)\n",
    "            \n",
    "            # Add state to maintain context\n",
    "            state = gr.State({})\n",
    "            \n",
    "            # Set up event handlers\n",
    "            upload_button.click(\n",
    "                fn=self.upload_csv,\n",
    "                inputs=[file_input],\n",
    "                outputs=[file_info, graph_output]\n",
    "            )\n",
    "            \n",
    "            submit_button.click(\n",
    "                fn=self.process_question,\n",
    "                inputs=[question_input, state],\n",
    "                outputs=[answer_output, graph_output, state]\n",
    "            )\n",
    "            \n",
    "            # Examples\n",
    "            gr.Examples(\n",
    "                examples=[\n",
    "                    [\"What is the average price?\"],\n",
    "                    [\"Show me a histogram of prices\"],\n",
    "                    [\"What is the correlation between square footage and price?\"],\n",
    "                    [\"Show me a scatter plot of price vs. square footage\"],\n",
    "                    [\"What are the top 5 most expensive neighborhoods?\"],\n",
    "                    [\"Create a bar chart showing average price by neighborhood\"]\n",
    "                ],\n",
    "                inputs=question_input\n",
    "            )\n",
    "            \n",
    "            gr.Markdown(\"\"\"\n",
    "            ## Tips for asking questions:\n",
    "            - Ask for statistics: \"What is the average/median/max of [column]?\"\n",
    "            - Ask for correlations: \"Is there a correlation between [column1] and [column2]?\"\n",
    "            - Request visualizations: \"Show me a [graph type] of [columns]\"\n",
    "            - Ask for trends: \"How does [column1] change with [column2]?\"\n",
    "            \"\"\")\n",
    "        \n",
    "        return app.launch(share=False)\n",
    "\n",
    "# Main application entry point\n",
    "if __name__ == \"__main__\":\n",
    "    app = GradioCSVApp()\n",
    "    app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1d831-d240-43e0-9b22-3c04a3db231c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
